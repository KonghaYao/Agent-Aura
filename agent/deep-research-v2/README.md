# Deep Research Agent V2 设计文档

本模块设计了一个能够进行深度网络搜索和信息整合的智能代理（Agent）。它模拟人类研究者的行为，通过多阶段的思考和执行循环来完成复杂的调研任务。

## 核心设计理念

Agent 的运作模拟了人类进行深度研究时的心智模型：**理解 -> 思考 -> 行动 -> 反思 -> 调整 -> 总结**。

### 1. 认知循环 (Cognitive Loop)

Agent 不仅仅是执行搜索命令，而是被设计在一个强制性的“思考-行动”循环中运行：

-   思考与规划 (Think & Plan): 在执行任何具体操作之前或之后，Agent 必须使用 `think_tool` 进行反思。这不仅仅是记录日志，而是强制模型通过输出其内部独白（Internal Monologue）来评估当前进度：
    -   我找到了什么？
    -   还缺什么信息？
    -   这些信息是否足以回答核心问题？
    -   下一步应该做什么？是继续深挖还是扩展搜索范围？
-   执行 (Execute): 根据思考的结果，调用搜索工具获取信息。
-   动态调整 (Adapt): 如果在搜索过程中发现原来的方向不对，或者发现了一个更有价值的切入点，Agent 有能力通过 `change_research_topic` 主动切换研究主题，而不是死板地坚持最初的路径。

### 2. 状态流转设计

Agent 的生命周期被划分为清晰的几个阶段，通过特定的工具调用来触发状态的流转：

-   探索阶段 (Exploration Phase):
    -   这是默认的初始状态。Agent 自由地使用搜索工具探索问题。
    -   它需要判断何时信息足够（Converge）或何时需要转向（Pivot）。
-   转向机制 (Pivot Mechanism):
    -   通过 `change_research_topic` 工具，Agent 可以显式地“归档”当前的研究成果，清空短期的上下文噪音，开启一个新的研究分支。这模拟了人类“先把这个问题放一放，看看那个方面”的思维切换。
-   收敛阶段 (Convergence Phase):
    -   当 Agent 判断已收集到足够的信息来回答用户的问题，或者达到了预设的资源限制时，它会调用 `end_of_research`。
    -   这标志着主动探索的结束，进入信息处理和产出阶段。

### 3. 信息处理架构

为了处理网络上获取的海量非结构化信息，设计采用了“分层压缩”的策略：

1. 原始获取: 首先获取大量相关的网页链接。
2. 并行抓取: 对选定的高质量链接进行全文抓取。
3. 语义压缩: 这是一个关键的设计点。不是直接将所有原文丢给最终模型，而是引入了一个中间步骤 —— **Topic Compression**。
    - 针对每个研究子主题，使用 LLM 对原始网页内容进行清洗和压缩。
    - 目标是去除网页噪音（广告、导航等）和冗余信息，同时**严格保留**关键事实、数据和引用来源。
4. 综合生成: 最终的报告生成器（Report Generator）接收的是经过清洗的高密度信息块，从而能够生成准确、详实且带有引用的最终报告。

### 4. 防幻觉与准确性设计

为了提高研究结果的可信度，设计中包含了以下原则：

-   强制引用: 在信息压缩和报告生成阶段，都明确要求保留和标注来源。
-   原始数据保留: 尽管进行了压缩，但关键的引用句（Quotes）和数据点（Data Points）被要求逐字（Verbatim）保留，防止在总结过程中产生语义漂移。
-   硬性限制: 设置了搜索次数的预算限制，防止 Agent 陷入无休止的搜索循环，迫使其在有限资源下通过策略优化来获取最佳答案。
